// AI Model Pricing Summary
// This file contains general information about AI model pricing

console.log('ğŸ’° AI MODEL PRICING INFORMATION:');
console.log('â•'.repeat(60));

console.log('\nğŸ† GENERAL PRICING GUIDELINES:');
console.log('â”€'.repeat(50));
console.log('â€¢ Model pricing varies by provider');
console.log('â€¢ Costs typically include input and output tokens');
console.log('â€¢ Some providers offer free tiers');
console.log('â€¢ Pricing may change over time');

console.log('\nğŸ“Š COST CONSIDERATIONS:');
console.log('â”€'.repeat(50));
console.log('â€¢ Larger models generally cost more');
console.log('â€¢ Streaming responses may have different pricing');
console.log('â€¢ Some providers offer discounted rates');

console.log('\nğŸ” RECOMMENDATIONS:');
console.log('â”€'.repeat(50));
console.log('â€¢ Compare pricing across providers');
console.log('â€¢ Consider your usage patterns');
console.log('â€¢ Check for promotional pricing');

console.log('\nğŸ“ NOTE:');
console.log('For the most current pricing information,');
console.log('please check the official provider documentation.');

console.log('\nğŸ† BEST VALUE: meta/llama-4-scout');
console.log('   ğŸ’° Only $0.0002 per 1M tokens total');
console.log('   ğŸ†• Latest Llama 4 technology');
console.log('   ğŸ‘ï¸ Multimodal (text + images)');
console.log('   ğŸš€ 17B parameters with 16 experts');

console.log('\nğŸ’¡ REMEMBER:');
console.log('âœ¨ Vercel gives you $5 free credits every 30 days');
console.log('ğŸ”„ All models work through your existing proxy');
console.log('ğŸ¯ For thinking models, use hide_thinking=true to see only final answers');
console.log('ğŸƒâ€â™‚ï¸ Models served by Groq are fastest');
console.log('ğŸ’° Prices shown are per 1 million tokens');

console.log('\nğŸ§ª Test any model with your proxy:');
console.log('curl -X POST "https://openai-proxy.alexandrite.workers.dev/v1/chat/completions" \\');
console.log('  -H "Authorization: Bearer YOUR_VERCEL_KEY" \\');
console.log('  -H "Content-Type: application/json" \\');
console.log('  -d \'{"model": "deepseek/deepseek-v3", "messages": [{"role": "user", "content": "Hello!"}]}\'');