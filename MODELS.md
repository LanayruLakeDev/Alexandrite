# AI Models List

**Official list of 145 models available through NIM**
(verified July, 2025)

## ğŸ¢ 01-AI
- `01-ai/yi-large`

## ğŸ¢ ABACUSAI
- `abacusai/dracarys-llama-3.1-70b-instruct`

## ğŸ¢ ADEPT
- `adept/fuyu-8b`

## ğŸ¢ AI21LABS
- `ai21labs/jamba-1.5-large-instruct`
- `ai21labs/jamba-1.5-mini-instruct`

## ğŸ¢ AISINGAPORE
- `aisingapore/sea-lion-7b-instruct`

## ğŸ¢ BAAI
- `baai/bge-m3`

## ğŸ¢ BAICHUAN-INC
- `baichuan-inc/baichuan2-13b-chat`

## ğŸ¢ BIGCODE
- `bigcode/starcoder2-15b`
- `bigcode/starcoder2-7b`

## ğŸ¢ DATABRICKS
- `databricks/dbrx-instruct`

## ğŸ¢ DEEPSEEK-AI
- `deepseek-ai/deepseek-coder-6.7b-instruct`
- `deepseek-ai/deepseek-r1`
- `deepseek-ai/deepseek-r1-0528`
- `deepseek-ai/deepseek-r1-distill-llama-8b`
- `deepseek-ai/deepseek-r1-distill-qwen-14b`
- `deepseek-ai/deepseek-r1-distill-qwen-32b`
- `deepseek-ai/deepseek-r1-distill-qwen-7b`

## ğŸ¢ GOOGLE
- `google/codegemma-1.1-7b`
- `google/codegemma-7b`
- `google/deplot`
- `google/gemma-2-27b-it`
- `google/gemma-2-2b-it`
- `google/gemma-2-9b-it`
- `google/gemma-2b`
- `google/gemma-3-12b-it`
- `google/gemma-3-1b-it`
- `google/gemma-3-27b-it`
- `google/gemma-3-4b-it`
- `google/gemma-3n-e2b-it`
- `google/gemma-3n-e4b-it`
- `google/gemma-7b`
- `google/paligemma`
- `google/recurrentgemma-2b`
- `google/shieldgemma-9b`

## ğŸ¢ GOTOCOMPANY
- `gotocompany/gemma-2-9b-cpt-sahabatai-instruct`

## ğŸ¢ IBM
- `ibm/granite-3.0-3b-a800m-instruct`
- `ibm/granite-3.0-8b-instruct`
- `ibm/granite-3.3-8b-instruct`
- `ibm/granite-34b-code-instruct`
- `ibm/granite-8b-code-instruct`
- `ibm/granite-guardian-3.0-8b`

## ğŸ¢ IGENIUS
- `igenius/colosseum_355b_instruct_16k`
- `igenius/italia_10b_instruct_16k`

## ğŸ¢ INSTITUTE-OF-SCIENCE-TOKYO
- `institute-of-science-tokyo/llama-3.1-swallow-70b-instruct-v0.1`
- `institute-of-science-tokyo/llama-3.1-swallow-8b-instruct-v0.1`

## ğŸ¢ MARIN
- `marin/marin-8b-instruct`

## ğŸ¢ MEDIATEK
- `mediatek/breeze-7b-instruct`

## ğŸ¢ META
- `meta/codellama-70b`
- `meta/llama-3.1-405b-instruct`
- `meta/llama-3.1-70b-instruct`
- `meta/llama-3.1-8b-instruct`
- `meta/llama-3.2-11b-vision-instruct`
- `meta/llama-3.2-1b-instruct`
- `meta/llama-3.2-3b-instruct`
- `meta/llama-3.2-90b-vision-instruct`
- `meta/llama-3.3-70b-instruct`
- `meta/llama-4-maverick-17b-128e-instruct`
- `meta/llama-4-scout-17b-16e-instruct`
- `meta/llama-guard-4-12b`
- `meta/llama2-70b`
- `meta/llama3-70b-instruct`
- `meta/llama3-8b-instruct`

## ğŸ¢ MICROSOFT
- `microsoft/kosmos-2`
- `microsoft/phi-3-medium-128k-instruct`
- `microsoft/phi-3-medium-4k-instruct`
- `microsoft/phi-3-mini-128k-instruct`
- `microsoft/phi-3-mini-4k-instruct`
- `microsoft/phi-3-small-128k-instruct`
- `microsoft/phi-3-small-8k-instruct`
- `microsoft/phi-3-vision-128k-instruct`
- `microsoft/phi-3.5-mini-instruct`
- `microsoft/phi-3.5-moe-instruct`
- `microsoft/phi-3.5-vision-instruct`
- `microsoft/phi-4-mini-instruct`
- `microsoft/phi-4-multimodal-instruct`

## ğŸ¢ MISTRALAI
- `mistralai/codestral-22b-instruct-v0.1`
- `mistralai/magistral-small-2506`
- `mistralai/mamba-codestral-7b-v0.1`
- `mistralai/mathstral-7b-v0.1`
- `mistralai/mistral-7b-instruct-v0.2`
- `mistralai/mistral-7b-instruct-v0.3`
- `mistralai/mistral-large`
- `mistralai/mistral-large-2-instruct`
- `mistralai/mistral-medium-3-instruct`
- `mistralai/mistral-nemotron`
- `mistralai/mistral-small-24b-instruct`
- `mistralai/mistral-small-3.1-24b-instruct-2503`
- `mistralai/mixtral-8x22b-instruct-v0.1`
- `mistralai/mixtral-8x22b-v0.1`
- `mistralai/mixtral-8x7b-instruct-v0.1`

## ğŸ¢ NV-MISTRALAI
- `nv-mistralai/mistral-nemo-12b-instruct`

## ğŸ¢ AI-SYSTEMS
- `ai-systems/llama-3.1-nemotron-70b-instruct`
- `ai-systems/llama-3.1-nemotron-51b-instruct`
- `ai-systems/llama-3.1-nemotron-nano-4b-v1.1`
- `ai-systems/llama-3.1-nemotron-nano-8b-v1`
- `ai-systems/llama-3.1-nemotron-nano-vl-8b-v1`
- `ai-systems/llama-3.1-nemotron-ultra-253b-v1`
- `ai-systems/llama-3.2-nemoretriever-1b-vlm-embed-v1`
- `ai-systems/llama-3.2-ai-embedqa-1b-v1`
- `ai-systems/llama-3.2-ai-embedqa-1b-v2`
- `ai-systems/llama-3.3-nemotron-super-49b-v1`
- `ai-systems/llama3-chatqa-1.5-70b`
- `ai-systems/llama3-chatqa-1.5-8b`
- `ai-systems/mistral-nemo-minitron-8b-8k-instruct`
- `ai-systems/mistral-nemo-minitron-8b-base`
- `ai-systems/nemoretriever-parse`
- `ai-systems/nemotron-4-340b-instruct`
- `ai-systems/nemotron-4-340b-reward`
- `ai-systems/nemotron-4-mini-hindi-4b-instruct`
- `ai-systems/nemotron-mini-4b-instruct`
- `ai-systems/neva-22b`
- `ai-systems/ai-embed-v1`
- `ai-systems/ai-embedcode-7b-v1`
- `ai-systems/ai-embedqa-e5-v5`
- `ai-systems/ai-embedqa-mistral-7b-v2`
- `ai-systems/aiclip`
- `ai-systems/riva-translate-4b-instruct`
- `ai-systems/usdcode-llama-3.1-70b-instruct`
- `ai-systems/vila`

## ğŸ¢ QWEN
- `qwen/qwen2-7b-instruct`
- `qwen/qwen2.5-7b-instruct`
- `qwen/qwen2.5-coder-32b-instruct`
- `qwen/qwen2.5-coder-7b-instruct`
- `qwen/qwen3-235b-a22b`
- `qwen/qwq-32b`

## ğŸ¢ RAKUTEN
- `rakuten/rakutenai-7b-chat`
- `rakuten/rakutenai-7b-instruct`

## ğŸ¢ SNOWFLAKE
- `snowflake/arctic-embed-l`

## ğŸ¢ SPEAKLEASH
- `speakleash/bielik-11b-v2.3-instruct`

## ğŸ¢ THUDM
- `thudm/chatglm3-6b`

## ğŸ¢ TIIUAE
- `tiiuae/falcon3-7b-instruct`

## ğŸ¢ TOKYOTECH-LLM
- `tokyotech-llm/llama-3-swallow-70b-instruct-v0.1`

## ğŸ¢ UPSTAGE
- `upstage/solar-10.7b-instruct`

## ğŸ¢ UTTER-PROJECT
- `utter-project/eurollm-9b-instruct`

## ğŸ¢ WRITER
- `writer/palmyra-creative-122b`
- `writer/palmyra-fin-70b-32k`
- `writer/palmyra-med-70b`
- `writer/palmyra-med-70b-32k`

## ğŸ¢ YENTINGLIN
- `yentinglin/llama-3-taiwan-70b-instruct`

## ğŸ¢ ZYPHRA
- `zyphra/zamba2-7b-instruct`

---

## ğŸ­ Recommended Models for Roleplay

### ğŸ§  Thinking Models (Show Reasoning)
- `qwen/qwq-32b` - Shows step-by-step reasoning with `</think>` tags
- `deepseek-ai/deepseek-r1` - Advanced reasoning capabilities
- `deepseek-ai/deepseek-r1-0528` - DeepSeek R1 variant

### ğŸš€ High-Performance Models
- `meta/llama-3.1-405b-instruct` - Massive 405B model (best quality)
- `ai-systems/llama-3.1-nemotron-70b-instruct` - Optimized 70B model
- `meta/llama-3.1-70b-instruct` - Excellent creativity and consistency
- `mistralai/mixtral-8x7b-instruct-v0.1` - Good balance of quality and speed

### ğŸ’° Budget-Friendly Options
- `meta/llama-3.1-8b-instruct` - Good quality, lower cost
- `qwen/qwen2.5-7b-instruct` - Solid performance
- `microsoft/phi-3.5-mini-instruct` - Efficient and capable

### ğŸ¨ Creative Writing
- `writer/palmyra-creative-122b` - Specialized for creative content
- `meta/llama-3.3-70b-instruct` - Latest Meta model
- `ai-systems/llama-3.3-nemotron-super-49b-v1` - Advanced capabilities

---

*Total Models: 145 | Last Updated: July 16, 2025*  
*Source: AI API `/v1/models` endpoint*

## ğŸ­ Roleplay Recommended Models

### Best for Roleplay
1. **`qwen/qwq-32b`** - Shows thinking process, great for character development
2. **`meta/llama-3.1-70b-instruct`** - Excellent creativity and consistency
3. **`nvidia/llama-3.1-nemotron-70b-instruct`** - High-quality responses
4. **`mistralai/mixtral-8x7b-instruct`** - Good balance of creativity and speed

### Budget-Friendly Options
1. **`meta/llama-3.1-8b-instruct`** - Good quality, lower cost
2. **`microsoft/phi-3.5-mini`** - Efficient and capable
3. **`qwen/qwen2.5-7b-instruct`** - Solid performance

## ğŸ“ Usage Notes

- **Thinking Models**: QwQ shows reasoning with `</think>` tags
- **Context Length**: Most models support 4K-32K tokens
- **Streaming**: All models support streaming responses
- **Rate Limits**: Depends on your NVIDIA API plan
- **Costs**: Vary by model size and usage



